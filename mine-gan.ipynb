{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport os\nimport numpy as np\nimport torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nimport matplotlib.pyplot as plt\nfrom tqdm.auto import tqdm\n\n#!pip install gensim\n#!pip install torchview\n#from torchview import draw_graph","metadata":{"execution":{"iopub.status.busy":"2023-05-10T23:22:55.873204Z","iopub.execute_input":"2023-05-10T23:22:55.873734Z","iopub.status.idle":"2023-05-10T23:22:55.882104Z","shell.execute_reply.started":"2023-05-10T23:22:55.873692Z","shell.execute_reply":"2023-05-10T23:22:55.880433Z"},"trusted":true},"execution_count":567,"outputs":[]},{"cell_type":"code","source":"path = \"../input/aalto-csvs/\"","metadata":{"execution":{"iopub.status.busy":"2023-05-10T23:22:55.884578Z","iopub.execute_input":"2023-05-10T23:22:55.886209Z","iopub.status.idle":"2023-05-10T23:22:55.898898Z","shell.execute_reply.started":"2023-05-10T23:22:55.886147Z","shell.execute_reply":"2023-05-10T23:22:55.897025Z"},"trusted":true},"execution_count":568,"outputs":[]},{"cell_type":"code","source":"features= ['pck_size', 'Ether_type', 'LLC_ctrl', \n           'EAPOL_version', 'EAPOL_type', 'IP_ihl', \n           'IP_tos', 'IP_len', 'IP_flags', 'IP_DF', \n           'IP_ttl', 'IP_options', 'ICMP_code', 'TCP_dataofs', \n           'TCP_FIN', 'TCP_ACK', 'TCP_window', 'UDP_len', \n           'DHCP_options', 'BOOTP_hlen', 'BOOTP_flags', 'BOOTP_sname', \n           'BOOTP_file', 'BOOTP_options', 'DNS_qr', 'DNS_rd', \n           'DNS_qdcount', 'dport_class', 'payload_bytes', 'entropy', 'Label']\nprint(\"Total features: \")\nprint(len(features))\n\npairs = {'Aria': 0, 'D-LinkCam': 1, 'D-LinkDayCam': 2, 'D-LinkDoorSensor': 3, 'D-LinkHomeHub': 4, 'D-LinkSensor': 5, \n         'D-LinkSiren': 6, 'D-LinkSwitch': 7, 'D-LinkWaterSensor': 8, 'EdimaxCam': 9, 'EdimaxPlug1101W': 10, \n         'EdimaxPlug2101W': 11, 'EdnetCam': 12, 'EdnetGateway': 13, 'HomeMaticPlug': 14, 'HueBridge': 15, 'HueSwitch': 16, \n         'IKettle2': 17, 'Lightify': 18, 'MAXGateway': 19, 'SmarterCoffee': 20, 'TP-LinkPlugHS100': 21, 'TP-LinkPlugHS110': 22,\n         'WeMoInsightSwitch': 23, 'WeMoLink': 24, 'WeMoSwitch': 25, 'Withings': 26}","metadata":{"execution":{"iopub.status.busy":"2023-05-10T23:22:55.900695Z","iopub.execute_input":"2023-05-10T23:22:55.901149Z","iopub.status.idle":"2023-05-10T23:22:55.916970Z","shell.execute_reply.started":"2023-05-10T23:22:55.901112Z","shell.execute_reply":"2023-05-10T23:22:55.915426Z"},"trusted":true},"execution_count":569,"outputs":[{"name":"stdout","text":"Total features: \n31\n","output_type":"stream"}]},{"cell_type":"code","source":"class IoTData(Dataset):\n    \"\"\"Dataset to read the csv files.\"\"\"\n    \n    # csv_file is the path to CSV file\n    def __init__(self, csv_file, lookup, transform=None):\n        \"\"\"\n        Args:\n            csv_file(string): path to CSV file to be read.\n            transform(callable, optional): Apply a transform on data\n        This is the initialization of IoTData.\n        \"\"\"\n        self.csv_file = pd.read_csv(csv_file, usecols=features)\n        self.transform = transform\n        self.lookup = lookup\n        \n    # Returns the length of initialized CSV file.\n    def __len__(self):\n        return len(self.csv_file)\n    \n    def __getitem__(self, idx):\n        \"\"\"\n        Args:\n            idx(integer): The index of row to sample from Dataset.\n        Returns:dict\n            keys(string, string):\"device\", \"data\"\n            values(string, tensor): Name of device, tensor of features for device\n        \"\"\"\n        data = self.csv_file.iloc[idx,:-1].astype(\"float64\")\n        data = torch.Tensor(data.values)\n        device = self.csv_file.iloc[idx,-1]\n        device = self.lookup[device]\n        sample={\"device\": device, \"data\": data}\n        if self.transform:\n            sample = self.transform(sample)\n        return sample","metadata":{"execution":{"iopub.status.busy":"2023-05-10T23:22:55.919853Z","iopub.execute_input":"2023-05-10T23:22:55.922100Z","iopub.status.idle":"2023-05-10T23:22:55.937371Z","shell.execute_reply.started":"2023-05-10T23:22:55.921958Z","shell.execute_reply":"2023-05-10T23:22:55.935861Z"},"trusted":true},"execution_count":570,"outputs":[]},{"cell_type":"code","source":"import torch.nn.functional as F\ndef get_one_hot_labels(labels, n_classes):\n    '''\n    Function for creating one-hot vectors for the labels, returns a tensor of shape (?, num_classes).\n    Parameters:\n        labels: tensor of labels from the dataloader, size (?)\n        n_classes: the total number of classes in the dataset, an integer scalar\n    '''\n    return F.one_hot(labels, num_classes=n_classes)","metadata":{"execution":{"iopub.status.busy":"2023-05-10T23:22:55.939358Z","iopub.execute_input":"2023-05-10T23:22:55.940550Z","iopub.status.idle":"2023-05-10T23:22:55.960868Z","shell.execute_reply.started":"2023-05-10T23:22:55.940479Z","shell.execute_reply":"2023-05-10T23:22:55.959170Z"},"trusted":true},"execution_count":571,"outputs":[]},{"cell_type":"code","source":"def get_noise(n_samples, z_dim, device):\n    return torch.randn(n_samples, z_dim, device=device)","metadata":{"execution":{"iopub.status.busy":"2023-05-10T23:22:55.963193Z","iopub.execute_input":"2023-05-10T23:22:55.965075Z","iopub.status.idle":"2023-05-10T23:22:55.976321Z","shell.execute_reply.started":"2023-05-10T23:22:55.965017Z","shell.execute_reply":"2023-05-10T23:22:55.974720Z"},"trusted":true},"execution_count":572,"outputs":[]},{"cell_type":"code","source":"def combine_tensors(x, y):\n    '''\n    Function for combining two tensors with shapes (n_samples, ?) and (n_samples, ?).\n    Parameters:\n      x: (n_samples, ?) the first tensor. \n      y: (n_samples, ?) the second tensor.\n    '''\n    combined = torch.cat((x.float(), y.float()), dim = 1)\n    return combined","metadata":{"execution":{"iopub.status.busy":"2023-05-10T23:22:55.977887Z","iopub.execute_input":"2023-05-10T23:22:55.978288Z","iopub.status.idle":"2023-05-10T23:22:55.990152Z","shell.execute_reply.started":"2023-05-10T23:22:55.978253Z","shell.execute_reply":"2023-05-10T23:22:55.988815Z"},"trusted":true},"execution_count":573,"outputs":[]},{"cell_type":"code","source":"class Reshape(nn.Module):\n    def __init__(self, *args):\n        super(Reshape, self).__init__()\n        self.shape = args\n\n    def forward(self, x):\n        return x.view(self.shape)","metadata":{"execution":{"iopub.status.busy":"2023-05-10T23:22:55.992018Z","iopub.execute_input":"2023-05-10T23:22:55.992690Z","iopub.status.idle":"2023-05-10T23:22:56.009280Z","shell.execute_reply.started":"2023-05-10T23:22:55.992640Z","shell.execute_reply":"2023-05-10T23:22:56.007151Z"},"trusted":true},"execution_count":574,"outputs":[]},{"cell_type":"code","source":"class Generator(nn.Module):\n    def __init__(self, input_dim, hidden_dim, out_dim):\n        super(Generator, self).__init__()\n        self.input_dim = input_dim\n        self.gen = nn.Sequential(\n            nn.Linear(input_dim, hidden_dim),\n            nn.Linear(hidden_dim, hidden_dim*2),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Linear(hidden_dim*2, hidden_dim*4),\n            nn.ReLU(inplace=True),\n            nn.Linear(hidden_dim*4, out_dim)\n        )\n    def forward(self, noise):\n        return self.gen(noise)","metadata":{"execution":{"iopub.status.busy":"2023-05-10T23:22:56.012447Z","iopub.execute_input":"2023-05-10T23:22:56.013749Z","iopub.status.idle":"2023-05-10T23:22:56.026648Z","shell.execute_reply.started":"2023-05-10T23:22:56.013571Z","shell.execute_reply":"2023-05-10T23:22:56.024892Z"},"trusted":true},"execution_count":575,"outputs":[]},{"cell_type":"code","source":"class Discriminator(nn.Module):\n    def __init__(self, input_dim, hidden_dim):\n        super(Discriminator, self).__init__()\n        self.input_dim = input_dim\n        self.disc = nn.Sequential(\n            nn.Linear(input_dim, hidden_dim),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Linear(hidden_dim, hidden_dim*2),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Linear(hidden_dim*2, hidden_dim*4),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Dropout(0.2),\n            nn.Linear(hidden_dim*4, 1),\n            nn.Sigmoid()\n        )\n    def forward(self, disc_input):\n        return self.disc(disc_input)","metadata":{"execution":{"iopub.status.busy":"2023-05-10T23:22:56.029675Z","iopub.execute_input":"2023-05-10T23:22:56.030443Z","iopub.status.idle":"2023-05-10T23:22:56.045943Z","shell.execute_reply.started":"2023-05-10T23:22:56.030366Z","shell.execute_reply":"2023-05-10T23:22:56.044077Z"},"trusted":true},"execution_count":576,"outputs":[]},{"cell_type":"code","source":"criterion = nn.BCEWithLogitsLoss()\nepoches = 5\nbatch_size = 128\nz_dim = 28\nlr=0.00001\ndisplay_step=500\nn_classes = 27\ngenerator_input_dim = z_dim + n_classes\nprint(generator_input_dim)\ndiscriminator_input_dim = len(features)-1 + n_classes\n\n\ntrain_data = IoTData(os.path.join(path, \"Aalto_train_IoTDevID.csv\"), pairs)\ntrain_data = DataLoader(train_data, shuffle=True, batch_size=batch_size, drop_last=True)\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(\"Running device:{}\".format(device))","metadata":{"execution":{"iopub.status.busy":"2023-05-10T23:22:56.048162Z","iopub.execute_input":"2023-05-10T23:22:56.050745Z","iopub.status.idle":"2023-05-10T23:22:56.572748Z","shell.execute_reply.started":"2023-05-10T23:22:56.050666Z","shell.execute_reply":"2023-05-10T23:22:56.571437Z"},"trusted":true},"execution_count":577,"outputs":[{"name":"stdout","text":"55\nRunning device:cpu\n","output_type":"stream"}]},{"cell_type":"code","source":"\"\"\"\nx = get_noise(1,10, device)\nmodel = Generator(10,20, 5).to(device)\ny = model(x)\nmodel_graph = draw_graph(model, input_size=(1,10), device='meta')\nmodel_graph.visual_graph\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2023-05-10T23:22:56.574453Z","iopub.execute_input":"2023-05-10T23:22:56.575614Z","iopub.status.idle":"2023-05-10T23:22:56.583742Z","shell.execute_reply.started":"2023-05-10T23:22:56.575567Z","shell.execute_reply":"2023-05-10T23:22:56.582450Z"},"trusted":true},"execution_count":578,"outputs":[{"execution_count":578,"output_type":"execute_result","data":{"text/plain":"\"\\nx = get_noise(1,10, device)\\nmodel = Generator(10,20, 5).to(device)\\ny = model(x)\\nmodel_graph = draw_graph(model, input_size=(1,10), device='meta')\\nmodel_graph.visual_graph\\n\""},"metadata":{}}]},{"cell_type":"code","source":"gen = Generator(generator_input_dim, 30, len(features)-1).to(device)\ngen_opt = torch.optim.Adam(gen.parameters(), lr=lr)\ndisc = Discriminator(discriminator_input_dim, 64).to(device)\ndisc_opt = disc_opt = torch.optim.Adam(disc.parameters(), lr=lr)","metadata":{"execution":{"iopub.status.busy":"2023-05-10T23:22:56.585658Z","iopub.execute_input":"2023-05-10T23:22:56.586065Z","iopub.status.idle":"2023-05-10T23:22:56.597782Z","shell.execute_reply.started":"2023-05-10T23:22:56.586029Z","shell.execute_reply":"2023-05-10T23:22:56.596437Z"},"trusted":true},"execution_count":579,"outputs":[]},{"cell_type":"code","source":"cur_step = 0\ntest_generator = True\ngenerator_losses = []\ndiscriminator_losses = []\n\nfor epoch in range(epoches):\n    for cur_batch in train_data:\n        reals = cur_batch[\"data\"]\n        labels = cur_batch[\"device\"]\n    # print(labels.dtype)\n    #    print(reals.shape)\n   #     print(labels.shape)\n        one_hots = get_one_hot_labels(labels, n_classes)\n    #    print(one_hots.dtype)\n        \n        disc.zero_grad()\n        noises = get_noise(batch_size, z_dim, device)\n #       print(noises.shape)\n        noise_with_labels = combine_tensors(noises, one_hots)\n#        print(noise_with_labels.dtype)\n        fakes = gen(noise_with_labels)\n   #     print(fakes.shape)\n        fakes_and_labels = combine_tensors(fakes.detach(), one_hots)\n        reals_and_labels = combine_tensors(reals, one_hots)\n        disc_fake_predictions = disc(fakes_and_labels)\n        disc_real_predictions = disc(reals_and_labels)\n\n        disc_fake_loss = criterion(disc_fake_predictions, torch.zeros_like(disc_fake_predictions))\n        disc_real_loss = criterion(disc_real_predictions, torch.ones_like(disc_real_predictions))\n        disc_loss = (disc_fake_loss + disc_real_loss) / 2\n        disc_loss.backward(retain_graph=True)\n        disc_opt.step() \n        discriminator_losses += [disc_loss.item()]\n        \n        gen_opt.zero_grad()\n        fake_image_and_labels = combine_tensors(fakes, one_hots)\n        disc_fake_pred = disc(fake_image_and_labels)\n        gen_loss = criterion(disc_fake_pred, torch.ones_like(disc_fake_pred))\n        gen_loss.backward()\n        gen_opt.step()\n        generator_losses += [gen_loss.item()]\n        \n        \"\"\"\n        disc_fake_predictions = disc(fakes.detach())\n        discriminator_loss = criterion(disc_fake_predictions, torch.zeros_like(disc_fake_predictions))\n        \n        discriminator_real_predictions = disc(reals)\n        discriminator_loss += criterion(discriminator_real_predictions, torch.ones_like(discriminator_real_predictions))\n        discriminator_loss/=2\n    \n        \n        \n        discriminator_loss.backward(retain_graph=True)\n        disc_opt.step()\n        mean_discriminator_loss += discriminator_loss.item()/display_step\n        \n        if test_generator:\n            old_generator_weights = gen.gen[0].weight.detach().clone()\n        \n        gen.zero_grad()\n        noise = get_noise(batch_size, z_dim, device)\n        fakes = gen(noise)\n        discriminator_predictions = disc(fakes)\n        generator_loss = criterion(discriminator_predictions, torch.ones_like(discriminator_predictions))\n        generator_loss.backward()\n        gen_opt.step()\n        \n        mean_generator_loss += generator_loss/display_step\n        if test_generator:\n            try:\n                assert lr > 0.0000002 or (gen.gen[0][0].weight.grad.abs().max() < 0.0005 and epoch == 0)\n                assert torch.any(gen.gen[0][0].weight.detach().clone() != old_generator_weights)\n            except:\n                error = True\n                print(\"Runtime tests have failed\")\n        \"\"\"\n        if (cur_step % display_step) == 0 and cur_step > 0:\n            mean_generator_loss = sum(generator_losses[-display_step:]) / display_step\n            mean_discriminator_loss = sum(discriminator_losses[-display_step:]) / display_step\n            print(\"Epoch : {} -- Step :{} -- Generator loss:{} -- Discriminator loss:{}\".format(epoch, cur_step, mean_generator_loss, mean_discriminator_loss))\n            noise = get_noise(1,z_dim,device)\n            lbls = get_one_hot_labels(torch.tensor([0]),n_classes)\n            noise_and_lbls = combine_tensors(noise, lbls)\n            fks = gen(noise_and_lbls)\n            print(fks)\n        cur_step+=1\n        if(cur_step%100 == 0):\n            print(cur_step)","metadata":{"execution":{"iopub.status.busy":"2023-05-10T23:22:56.602086Z","iopub.execute_input":"2023-05-10T23:22:56.602857Z","iopub.status.idle":"2023-05-10T23:27:42.181261Z","shell.execute_reply.started":"2023-05-10T23:22:56.602808Z","shell.execute_reply":"2023-05-10T23:27:42.179501Z"},"trusted":true},"execution_count":580,"outputs":[{"name":"stdout","text":"100\n200\n300\n400\n500\nEpoch : 0 -- Step :500 -- Generator loss:0.47779188495874403 -- Discriminator loss:0.6461662467718124\ntensor([[-0.0066,  0.1291,  0.0756,  0.1102, -0.0470, -0.0088,  0.1488,  0.0880,\n         -0.0683,  0.0581, -0.0141, -0.1388, -0.0765,  0.0825, -0.0988,  0.0308,\n          0.0217, -0.0254,  0.0167,  0.0680, -0.0026,  0.0471, -0.1011,  0.0741,\n         -0.0280,  0.0134,  0.1287,  0.2087,  0.0744, -0.1197]],\n       grad_fn=<AddmmBackward0>)\n600\n700\n800\n900\n1000\nEpoch : 1 -- Step :1000 -- Generator loss:0.4860586279630661 -- Discriminator loss:0.6341708116531372\ntensor([[-0.0456,  0.1943,  0.0748,  0.2024, -0.1091,  0.0583,  0.2203,  0.1653,\n         -0.0363,  0.0818,  0.0038, -0.0697, -0.1107,  0.1777, -0.1117,  0.1085,\n          0.0146, -0.0332,  0.0118,  0.0805, -0.0527,  0.1194, -0.1259,  0.0864,\n         -0.0414,  0.0016,  0.1059,  0.1814, -0.0113, -0.2259]],\n       grad_fn=<AddmmBackward0>)\n1100\n1200\n1300\n1400\n1500\nEpoch : 2 -- Step :1500 -- Generator loss:0.49854406994581224 -- Discriminator loss:0.6243876739740372\ntensor([[ 0.1187,  0.3464, -0.0137,  0.3605, -0.0445,  0.0830,  0.1325,  0.2168,\n          0.0154, -0.0425,  0.1178,  0.0779, -0.1021,  0.2053, -0.1083,  0.0457,\n          0.2712,  0.2571, -0.1786, -0.0138, -0.1117,  0.0294, -0.0881,  0.1300,\n         -0.0028, -0.0419,  0.0415,  0.0804, -0.0028, -0.1510]],\n       grad_fn=<AddmmBackward0>)\n1600\n1700\n1800\n1900\n2000\nEpoch : 3 -- Step :2000 -- Generator loss:0.5159186170101165 -- Discriminator loss:0.6113593384027481\ntensor([[ 3.4630e-01,  4.0854e-01, -7.6636e-02,  7.8030e-02,  1.1557e-04,\n         -3.8828e-02, -8.4859e-02,  2.0425e-01, -6.1232e-02, -1.7528e-01,\n          2.5269e-01,  4.7890e-02,  3.6857e-02,  2.0364e-01, -3.1611e-02,\n         -9.7767e-02,  4.1666e-01,  3.3915e-01, -2.7330e-01, -7.2137e-02,\n         -1.5193e-01, -2.0043e-01,  4.8963e-02, -7.1480e-02, -4.9458e-02,\n         -1.0849e-02, -6.5975e-02, -9.6838e-02,  1.3279e-01, -7.8068e-02]],\n       grad_fn=<AddmmBackward0>)\n2100\n2200\n2300\n2400\n2500\nEpoch : 3 -- Step :2500 -- Generator loss:0.5385698761940002 -- Discriminator loss:0.5952065893411637\ntensor([[ 1.1230,  1.6595,  0.0077, -0.1161,  0.0975,  0.0987, -0.6306,  0.1177,\n          0.1425, -0.2559,  0.1530,  0.0531,  0.3409, -0.0340,  0.3151, -0.0533,\n          1.2876,  0.8860, -0.3538, -0.1250,  0.0079, -0.1500,  0.5309, -0.0284,\n          0.0804, -0.0518, -0.1306, -0.5634,  0.4697,  0.2988]],\n       grad_fn=<AddmmBackward0>)\n2600\n2700\n2800\n2900\n3000\nEpoch : 4 -- Step :3000 -- Generator loss:0.571046313047409 -- Discriminator loss:0.5734396755695343\ntensor([[ 0.9813,  1.8622,  0.1074, -0.4254,  0.0181,  0.0754, -0.7774,  0.3756,\n         -0.1880,  0.0750, -0.2454, -0.0388,  0.0348, -0.2785,  0.1111, -0.2138,\n          1.8891,  1.0654,  0.1831,  0.1899,  0.5095,  0.3276,  0.5442,  0.3022,\n         -0.1868,  0.0884,  0.1283, -0.6451,  0.2719,  0.1043]],\n       grad_fn=<AddmmBackward0>)\n3100\n3200\n","output_type":"stream"}]}]}